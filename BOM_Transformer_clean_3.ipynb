{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c51a758-0662-44d6-8b86-dae502d4d90b",
   "metadata": {},
   "source": [
    "# Importing data and preparing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302675dd-0949-4d66-b5e2-e8ec8739f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    # Load and prepare the primary dataframe `df`\n",
    "    df = pd.read_csv(\"V01_PIA_MONTHLY_BOM.csv\", low_memory=False)\n",
    "    \n",
    "    # Data type corrections and filtering for `df`\n",
    "    df['OUTPUT_MATERIAL_ID'] = df['OUTPUT_MATERIAL_ID'].astype(str)\n",
    "    df['MONTHLY_DATE'] = pd.to_datetime(df['MONTHLY_DATE'])\n",
    "    df = df[df['TOTAL_OUTPUT_QTY'] != 0].reset_index(drop=True)  # Remove rows with TOTAL_OUTPUT_QTY == 0\n",
    "    df = df[df['MONTHLY_DATE'].dt.year == 2023].reset_index(drop=True)  # Filter for year 2022\n",
    "\n",
    "    # Selecting the required columns\n",
    "    selected_columns = df[\n",
    "        ['MONTHLY_DATE', 'PLANT_ID', 'COMPONENT_ID', 'TOTAL_INPUT_QTY',\n",
    "         'FINAL_COMPONENT_UOM', 'TOTAL_INPUT_MASS', 'OUTPUT_MATERIAL_ID',\n",
    "         'TOTAL_OUTPUT_QTY', 'TOTAL_OUTPUT_MASS', 'FINAL_OUTPUT_MATERIAL_UOM','COMPONENT_DESC','COMPONENT_MATERIAL_TYPE',\n",
    "         'COMPONENT_MASS_CONV_FACTOR', 'COMPONENT_MASS_UNIT', 'OUTPUT_MASS_CONV_FACTOR',\t'OUTPUT_MASS_UNIT',\t'OUTPUT_MATERIAL_DESC',\t'OUTPUT_MATERIAL_TYPE']\n",
    "    ]\n",
    "\n",
    "    # Apply grouping functionality\n",
    "    df = selected_columns.groupby(\n",
    "        ['COMPONENT_ID', 'OUTPUT_MATERIAL_ID'], as_index=False, sort=False\n",
    "    ).agg({\n",
    "        'TOTAL_INPUT_QTY': 'sum',       # Sum the 'TOTAL_INPUT_QTY' column\n",
    "        'TOTAL_OUTPUT_QTY': 'sum',      # Sum the 'TOTAL_OUTPUT_QTY' column\n",
    "        'FINAL_COMPONENT_UOM': 'first', # Keep the first 'FINAL_COMPONENT_UOM' value\n",
    "        'PLANT_ID': 'first',            # Keep the first 'PLANT_ID' value\n",
    "        'FINAL_COMPONENT_UOM':'first',# Add more aggregation functions as needed\n",
    "        'FINAL_OUTPUT_MATERIAL_UOM':'first',\n",
    "        'COMPONENT_MATERIAL_TYPE': 'first',\n",
    "        'COMPONENT_DESC':'first',\n",
    "        'COMPONENT_MASS_CONV_FACTOR':'first',\n",
    "        'COMPONENT_MASS_UNIT': 'first',\n",
    "        # the following stuff is for level 0 item\n",
    "        'OUTPUT_MASS_CONV_FACTOR':'first',\n",
    "        'OUTPUT_MASS_UNIT':'first',\n",
    "        'OUTPUT_MATERIAL_DESC':'first',\n",
    "        'OUTPUT_MATERIAL_TYPE':'first'\n",
    "        \n",
    "    })\n",
    "\n",
    "    # Load other datasets without additional processing\n",
    "    plant = pd.read_csv('3M data/V01_PLANT.csv')\n",
    "    plant_loc = pd.read_csv('3M data/V01_PIA_SUPPLIER_LOCATION_5-12-24.csv', low_memory=False)\n",
    "    \n",
    "    # Load and prepare `CDMS_DATA`\n",
    "    CDMS_DATA = pd.read_csv(\"3M data/V01_CDMS_DATA.csv\")\n",
    "    CDMS_DATA['SAP_ID'] = CDMS_DATA['SAP_ID'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "    CDMS_DATA['CAS_'] = CDMS_DATA['CAS_'].fillna(\"\")\n",
    "    return df, plant, plant_loc, CDMS_DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ece346-5181-4855-b4ca-64ac0809215a",
   "metadata": {},
   "source": [
    "# building adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f717ce24-6731-41e3-a0ce-d721655f244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def create_adj_list(df):\n",
    "    # Filter data by the specified year, the following step is not needed since it happens when importing the data\n",
    "    # filtered_data = df[df['MONTHLY_DATE'].dt.year == int(year)]\n",
    "    \n",
    "    adj_full = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iterate through each row in the filtered data\n",
    "    for row in df.itertuples():\n",
    "        output_material_id = row.OUTPUT_MATERIAL_ID\n",
    "        component_id = row.COMPONENT_ID\n",
    "        row_index = row.Index  # Row index in filtered data\n",
    "\n",
    "        # Add component_id and row index to adj_full dictionary\n",
    "        if output_material_id in adj_full:\n",
    "            adj_full[output_material_id].append((component_id, row_index))\n",
    "        else:\n",
    "            adj_full[output_material_id] = [(component_id, row_index)]\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "\n",
    "    return adj_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787386d3-18af-43a8-879e-5efa8e2ab345",
   "metadata": {},
   "source": [
    "# creating a BOM dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8d0bec-004d-481d-969e-3c64fa319f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dfs\n",
    "\n",
    "color = {}\n",
    "\n",
    "def dfs(component_id, adj_full, ans, level):\n",
    "\n",
    "    color[component_id] = 1 # marking the node as grey - in progress or being processed \n",
    "    \n",
    "    for child, index in adj_full.get(component_id, []):# Retrieve each child and its index from adj_full\n",
    "\n",
    "        if color.get(child) != 1:\n",
    "            \n",
    "            ans.append((child, index, level))  # Add each child as a tuple (child, index, level)\n",
    "            dfs(child, adj_full, ans, level + 1)  # Recursively call dfs on each child and increase the level\n",
    "\n",
    "\n",
    "    color[component_id] = 2 # marking the node as black - processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2504cf-cc51-46df-b79f-7491a4ddf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(component_id, adj_full, ans, level):\n",
    "    \"\"\"\n",
    "    Perform depth-first search to traverse the tree and collect descendants\n",
    "    with their corresponding index and level.\n",
    "\n",
    "    :param component_id: The current node (component) being processed.\n",
    "    :param adj_full: The adjacency list (dict) containing the graph of components.\n",
    "    :param ans: The list to store the result tuples (child, index, level).\n",
    "    :param level: The current depth level in the tree.\n",
    "    \"\"\"\n",
    "    for child, index in adj_full.get(component_id, []):  # Retrieve each child and its index from adj_full\n",
    "        ans.append((child, index, level))  # Add each child as a tuple (child, index, level)\n",
    "        dfs(child, adj_full, ans, level + 1)  # Recursively call dfs on each child and increase the level\n",
    "\n",
    "\n",
    "def build_bom_dataframe(component_id, adj_full, df):\n",
    "    \"\"\"\n",
    "    Build the BOM dataframe based on the component's tree structure from the adjacency list.\n",
    "\n",
    "    :param component_id: The starting component ID to initiate the DFS.\n",
    "    :param adj_full: The adjacency list (dict) containing the graph of components.\n",
    "    :param df: The original dataframe containing the component details.\n",
    "    :return: A new dataframe containing the descendants of the component with their corresponding levels.\n",
    "    \"\"\"\n",
    "    ans = []  # Initialize the list to store (child, index, level) tuples\n",
    "    \n",
    "    # Perform DFS starting from the given component_id\n",
    "    dfs(component_id, adj_full, ans, level=1)\n",
    "    \n",
    "    # Extract the indexes and levels from the DFS result\n",
    "    indexes = [t[1] for t in ans]  # Extract all the second elements (indexes)\n",
    "    levels = [t[2] for t in ans]   # Extract all the third elements (levels)\n",
    "\n",
    "    # Select the rows from the DataFrame using the extracted indexes\n",
    "    new_dataframe = df.iloc[indexes].copy()\n",
    "\n",
    "    # Add the 'Level' column to the new dataframe\n",
    "    new_dataframe['Level'] = levels\n",
    "    new_new_dataframe = new_dataframe.reset_index(drop=True)\n",
    "    return new_new_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb9010d-2f86-4e19-b950-de57e5f56338",
   "metadata": {},
   "source": [
    "# Preparing for the scalling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ed9399-7a0a-4bca-a9a5-70bb28001ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_and_aggregate(bom_dataframe, component_id, df):\n",
    "    # Find the FINAL_COMPONENT_UOM for the given COMPONENT_ID. the following to fetch informaiton for the root node\n",
    "    final_component_uom = df.loc[df['OUTPUT_MATERIAL_ID'] == component_id, 'FINAL_OUTPUT_MATERIAL_UOM'].values[0]\n",
    "    OUTPUT_MATERIAL_DESC = df.loc[df['OUTPUT_MATERIAL_ID'] == component_id, 'OUTPUT_MATERIAL_DESC'].values[0]\n",
    "    OUTPUT_MATERIAL_TYPE = df.loc[df['OUTPUT_MATERIAL_ID'] == component_id, 'OUTPUT_MATERIAL_TYPE'].values[0]\n",
    "    OUTPUT_MASS_CONV_FACTOR = df.loc[df['OUTPUT_MATERIAL_ID'] == component_id, 'OUTPUT_MASS_CONV_FACTOR'].values[0]\n",
    "    OUTPUT_MASS_UNIT = df.loc[df['OUTPUT_MATERIAL_ID'] == component_id, 'OUTPUT_MASS_UNIT'].values[0]\n",
    "    PLANT_ID = df.loc[df['OUTPUT_MATERIAL_ID'] == component_id, 'PLANT_ID'].values[0]\n",
    "    \n",
    "    # Extract component-specific totals into a dictionary\n",
    "    result_dict = {\n",
    "        row['COMPONENT_ID']: {\n",
    "            'TOTAL_INPUT_QTY': row['TOTAL_INPUT_QTY'],\n",
    "            'TOTAL_OUTPUT_QTY': row['TOTAL_OUTPUT_QTY']\n",
    "        }\n",
    "        for _, row in bom_dataframe.iterrows()\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    # Create a default row using the provided component_id and its FINAL_COMPONENT_UOM\n",
    "    default_row = pd.DataFrame({\n",
    "        'Level': [0],\n",
    "        'COMPONENT_ID': [component_id],  # Use the input component_id instead of the hardcoded value\n",
    "        'TOTAL_INPUT_QTY': [1],\n",
    "        'FINAL_COMPONENT_UOM': [final_component_uom],  # Use the fetched FINAL_COMPONENT_UOM\n",
    "       'COMPONENT_DESC': [OUTPUT_MATERIAL_DESC],\n",
    "       'COMPONENT_MATERIAL_TYPE': [OUTPUT_MATERIAL_TYPE],\n",
    "        'COMPONENT_MASS_CONV_FACTOR': [OUTPUT_MASS_CONV_FACTOR],\n",
    "        'COMPONENT_MASS_UNIT':[OUTPUT_MASS_UNIT],\n",
    "        'PLANT_ID':[PLANT_ID]\n",
    "    })\n",
    "    \n",
    "    bom_dataframe = pd.concat([default_row, bom_dataframe], ignore_index=True)\n",
    "\n",
    "    # Define the desired column order\n",
    "    desired_column_order = ['Level', 'PLANT_ID', 'COMPONENT_ID', 'COMPONENT_DESC','COMPONENT_MATERIAL_TYPE', 'TOTAL_INPUT_QTY', 'FINAL_COMPONENT_UOM','COMPONENT_MASS_CONV_FACTOR','COMPONENT_MASS_UNIT']  # Example order\n",
    "\n",
    "    bom_dataframe = bom_dataframe[desired_column_order]\n",
    "    \n",
    "    return bom_dataframe, result_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693cd62-7bd8-46ae-b7de-770faa93dad3",
   "metadata": {},
   "source": [
    "# scalling quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6a66d8-5ced-4061-a087-17d37b7b4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_quantities(grouped_df, result_dict):\n",
    "    # Dictionary to store scaled quantities\n",
    "    scaled_quantity_dict = {}\n",
    "\n",
    "    # Iterate through grouped_df to scale TOTAL_INPUT_QTY\n",
    "    for index, row in grouped_df.iterrows():\n",
    "        component_id = row['COMPONENT_ID']\n",
    "        level = row['Level']\n",
    "        \n",
    "        if level == 0:\n",
    "            # For top-level items, retain original TOTAL_INPUT_QTY\n",
    "            scaled_quantity_dict[component_id] = row['TOTAL_INPUT_QTY']\n",
    "        else:\n",
    "            # Calculate scaled TOTAL_INPUT_QTY based on scaling_dict\n",
    "            total_input_qty = result_dict[component_id]['TOTAL_INPUT_QTY']\n",
    "            total_output_qty = result_dict[component_id]['TOTAL_OUTPUT_QTY']\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if total_output_qty != 0:\n",
    "                scaled_qty = total_input_qty / total_output_qty\n",
    "            else:\n",
    "                scaled_qty = 0  # Default to 0 if the output quantity is zero\n",
    "            \n",
    "            scaled_quantity_dict[component_id] = scaled_qty\n",
    "\n",
    "    # Update grouped_df with scaled quantities\n",
    "    grouped_df['TOTAL_INPUT_QTY'] = grouped_df['COMPONENT_ID'].map(scaled_quantity_dict)\n",
    "\n",
    "    return grouped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04fa25e-0c67-4892-bbf0-8bd4f2acebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_input_quantities_by_level(grouped_df):\n",
    "    # Dictionary to keep track of the last quantity seen at each level\n",
    "    last_level_qty = {}\n",
    "\n",
    "    # Iterate over each row in the grouped_df\n",
    "    for idx, row in grouped_df.iterrows():\n",
    "        level = row['Level']\n",
    "        item_id = row['COMPONENT_ID']\n",
    "        \n",
    "        if level == 0:\n",
    "            # Top-level item, keep its quantity as it is\n",
    "            last_level_qty[level] = row['TOTAL_INPUT_QTY']\n",
    "        else:\n",
    "            # Parent is the item at the previous level (level - 1)\n",
    "            parent_qty = last_level_qty[level - 1]\n",
    "            \n",
    "            # Multiply the current item’s quantity by the parent's quantity\n",
    "            row['TOTAL_INPUT_QTY'] *= parent_qty\n",
    "            \n",
    "            # Update the DataFrame with the new quantity\n",
    "            grouped_df.at[idx, 'TOTAL_INPUT_QTY'] = row['TOTAL_INPUT_QTY']\n",
    "            \n",
    "            # Update last_level_qty for this level\n",
    "            last_level_qty[level] = row['TOTAL_INPUT_QTY']\n",
    "\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abaf094c-278c-455d-adec-27e7e6217f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_leaf_status(grouped_df):\n",
    "    # Initialize the 'is_leaf' column to 'Yes' for all items\n",
    "    grouped_df['is_leaf'] = 'Yes'\n",
    "\n",
    "    # Iterate over the DataFrame rows to check each item\n",
    "    for i in range(len(grouped_df) - 1):\n",
    "        # If the next item's level is greater than the current item's level,\n",
    "        # then the current item has a child and is not a leaf\n",
    "        if grouped_df.loc[i + 1, 'Level'] > grouped_df.loc[i, 'Level']:\n",
    "            grouped_df.loc[i, 'is_leaf'] = 'No'\n",
    "\n",
    "    return grouped_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201136b8-1011-4821-b6a1-7f076a054965",
   "metadata": {},
   "source": [
    "# Geography enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4974458b-2065-43e0-b365-6c4127fb39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_supplier_geo(plant, plant_loc, grouped_df):\n",
    "    # Initialize new columns in grouped_df\n",
    "    grouped_df['Supplier'] = None\n",
    "    grouped_df['Geo_1'] = None\n",
    "\n",
    "    # Loop through each row in grouped_df\n",
    "    for idx, row in grouped_df.iterrows():\n",
    "        # Check if the row is a non-leaf\n",
    "        if row['is_leaf'] == 'No':\n",
    "            # Find matching plant information\n",
    "            plant_info = plant[plant['PLANT_ID'] == row['PLANT_ID']]\n",
    "            \n",
    "            # If a match is found, use the first match\n",
    "            if not plant_info.empty:\n",
    "                plant_info = plant_info.iloc[0]  # Get the first match\n",
    "                \n",
    "                # Fill Supplier from DESCRIPTION\n",
    "                grouped_df.at[idx, 'Supplier'] = plant_info['DESCRIPTION']\n",
    "                \n",
    "                # Check for Geo_1\n",
    "                latitude = plant_info['LATITUDE']\n",
    "                longitude = plant_info['LONGITUDE']\n",
    "                if (latitude != 0) and (longitude != 0):\n",
    "                    grouped_df.at[idx, 'Geo_1'] = f\"{latitude}, {longitude}\"\n",
    "                else:\n",
    "                    # If Geo_1 is not valid, construct Geo_1 from address components\n",
    "                    address_parts = [\n",
    "                        plant_info['STREET_ADDRESS'],\n",
    "                        plant_info['CITY'],\n",
    "                        plant_info['STATE'],\n",
    "                        plant_info['COUNTRY']\n",
    "                    ]\n",
    "                    address_parts = [part for part in address_parts if part not in [None, 'unknown']]\n",
    "                    grouped_df.at[idx, 'Geo_1'] = ', '.join(address_parts)\n",
    "\n",
    "        # Check if the row is a leaf\n",
    "        elif row['is_leaf'] == 'Yes':\n",
    "            # Find matching plant_loc information\n",
    "            loc_info = plant_loc[\n",
    "                (plant_loc['MATERIAL_ID'] == row['COMPONENT_ID']) &\n",
    "                (plant_loc['PLANT_ID'] == row['PLANT_ID'])\n",
    "            ]\n",
    "            \n",
    "            # If a match is found, use the first match\n",
    "            if not loc_info.empty:\n",
    "                loc_info = loc_info.iloc[0]  # Get the first match\n",
    "                \n",
    "                # Fill Supplier and Geo_1 for leaf nodes\n",
    "                grouped_df.at[idx, 'Supplier'] = loc_info['SUPPLIER_ID']\n",
    "                grouped_df.at[idx, 'Geo_1'] = loc_info['SUPPLIER_COUNTRY_CODE']\n",
    "\n",
    "    # Return the final enriched DataFrame\n",
    "    return grouped_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23819e2-7f22-4647-b018-6c2bf3311e63",
   "metadata": {},
   "source": [
    "# Composition enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434721b6-c2da-48d5-8299-a08d7327408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cdms_matches_to_grouped_df(grouped_df, CDMS_DATA):\n",
    "    # Function to find matches in CDMS_DATA based on STOCK_NUMBER or SAP_ID\n",
    "    def get_matches(component_id):\n",
    "        # Find matches in CDMS_DATA where either STOCK_NUMBER or SAP_ID matches the COMPONENT_ID\n",
    "        matches = CDMS_DATA[(CDMS_DATA['STOCK_NUMBER'] == component_id) | (CDMS_DATA['SAP_ID'] == component_id)]\n",
    "        # Return the matching rows as dictionaries for COMPONENT_NAME, CAS_, and MAX_VALUE\n",
    "        return matches[['COMPONENT_NAME', 'CAS_', 'MAX_VALUE']].to_dict(orient='records')\n",
    "\n",
    "    # Populate the 'temp' column with matches based on the logic\n",
    "    grouped_df['temp'] = grouped_df.apply(\n",
    "        lambda row: get_matches(row['COMPONENT_ID']) if row['is_leaf'] == 'Yes' else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Return the updated grouped_df\n",
    "    return grouped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b3e0a9-472d-4a55-b5ed-374ccad705a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def expand_grouped_df(grouped_df):\n",
    "    # Initialize an empty list to hold the final expanded rows\n",
    "    expanded_rows = []\n",
    "\n",
    "    # Iterate through each row in grouped_df\n",
    "    for _, row in grouped_df.iterrows():\n",
    "        # Append the original row to expanded_rows as-is\n",
    "        expanded_rows.append(row.to_dict())\n",
    "\n",
    "        # Check if 'temp' column has non-empty matches\n",
    "        if row['temp'] is not None and len(row['temp']) > 0:\n",
    "            # For each match in 'temp', create a new row with only the required columns filled\n",
    "            for match in row['temp']:\n",
    "                # Only proceed if CAS_ is valid (not NaN or empty)\n",
    "                if pd.notna(match.get('CAS_')): # removing the part that checks for empty CAS == and match.get('CAS_'): ==  # Safely access 'CAS_' with get()\n",
    "                    # Start a new row with all columns set to None initially\n",
    "                    new_row = {col: None for col in grouped_df.columns}\n",
    "\n",
    "                    # Populate only the specified columns\n",
    "                    new_row.update({\n",
    "                        'COMPONENT_ID': 'chemical',  # You can retain row['COMPONENT_ID'] if needed for reference\n",
    "                        'is_leaf': 'No',  # Indicate this is an expanded row\n",
    "                        'Amount': match.get('MAX_VALUE', 0) * row['TOTAL_INPUT_QTY'],  # MAX_VALUE from match * amount of parent, default to 0\n",
    "                        'Level': row['Level'] + 1,  # Increase Level by 1\n",
    "                        'Name': match.get('COMPONENT_NAME', ''),  # COMPONENT_NAME from the match\n",
    "                        'CAS_': match.get('CAS_'),  # CAS_ from the match\n",
    "                        'Geo_1': row['Geo_1'],\n",
    "                        'Max_proportion': match.get('MAX_VALUE', 0)  # Default to 0 if MAX_VALUE is missing\n",
    "                    })\n",
    "\n",
    "                    # Append the new row to expanded_rows\n",
    "                    expanded_rows.append(new_row)\n",
    "        else:\n",
    "            # If 'temp' is None or empty, add a row with empty values but inherit key columns\n",
    "            empty_row = {col: None for col in grouped_df.columns}\n",
    "            \n",
    "            # Set necessary columns to maintain structure\n",
    "            empty_row.update({\n",
    "                'COMPONENT_ID': 'chemical', # or use row['COMPONENT_ID'],\n",
    "                'is_leaf': 'Yes',  # Could indicate this is an unexpanded row\n",
    "                'Level': row['Level'],  # Keep the same level as the original row\n",
    "                'Geo_1': row['Geo_1'],\n",
    "                'Amount': None,\n",
    "                'Max_proportion': None,\n",
    "                'Name': None,\n",
    "                'CAS_': None\n",
    "            })\n",
    "            \n",
    "            # Append the empty row to expanded_rows\n",
    "            expanded_rows.append(empty_row)\n",
    "\n",
    "    # Convert expanded_rows to a DataFrame\n",
    "    final_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "    # Drop 'temp' column if it exists\n",
    "    final_df = final_df.drop(columns=['temp'], errors='ignore')\n",
    "\n",
    "    # Return the final dataframe\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f5155c2-ece1-4e6b-9476-91ca14b71762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def final_rescaling(final_df):\n",
    "    # Step 1: Identify the start of each new chemical group\n",
    "    final_df['Is_New_Group'] = (\n",
    "        (final_df['COMPONENT_ID'] != 'chemical') & \n",
    "        (final_df['COMPONENT_ID'].shift(-1) == 'chemical')\n",
    "    ).shift(fill_value=False).cumsum()\n",
    "\n",
    "    # Step 2: Filter to include only rows with chemicals\n",
    "    chemical_subelements = final_df[final_df['COMPONENT_ID'] == 'chemical']\n",
    "\n",
    "    # Step 3: Group by 'Is_New_Group' and calculate the sum of 'Max_proportion' for each group\n",
    "    chemical_sums = chemical_subelements.groupby('Is_New_Group')['Max_proportion'].transform('sum')\n",
    "\n",
    "    # Step 4: Calculate 'TOTAL_INPUT_QTY' for each chemical based on 'Amount' and the group's 'Max_proportion' sum\n",
    "    final_df.loc[final_df['COMPONENT_ID'] == 'chemical', 'TOTAL_INPUT_QTY'] = (\n",
    "        chemical_subelements['Amount'] / chemical_sums\n",
    "    )\n",
    "    final_df.drop(final_df[(final_df['COMPONENT_ID'] == 'chemical') & (final_df['Name'].isna()) & (final_df['CAS_'].isna())].index, inplace=True)\n",
    "\n",
    "    final_df.drop(columns=['is_leaf', 'Is_New_Group','Amount'], inplace=True)\n",
    "    # Return the final DataFrame with rescaling applied\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a13f85c-9a65-477c-ad79-4ef36f65375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extra_bom_modifications(df):\n",
    "    \"\"\"\n",
    "    Perform specific modifications to a dataframe for rows where COMPONENT_ID == 'chemical'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Modified dataframe with changes applied.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    modified_df = df.copy()\n",
    "    \n",
    "    # Perform modifications where COMPONENT_ID == 'chemical'\n",
    "    mask = modified_df['COMPONENT_ID'] == 'chemical'\n",
    "    modified_df.loc[mask, 'TOTAL_INPUT_QTY'] *= 0.453592  # Convert from LB to KG\n",
    "    modified_df.loc[mask, 'FINAL_COMPONENT_UOM'] = 'KG'   # Update unit to KG\n",
    "    modified_df.loc[mask, 'COMPONENT_ID'] = modified_df.loc[mask, 'Name']  # Replace 'chemical' with actual name\n",
    "\n",
    "    # Reset the index\n",
    "    modified_df.reset_index(drop=True, inplace=True)\n",
    "    return modified_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e7e7caf-6c1e-4042-bc5b-20d4bc838894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def extra_bom_modifications_2(final_df, plant):\n",
    "    # Create a copy of the plant DataFrame to work on\n",
    "    plant_copy = plant.copy()\n",
    "\n",
    "    # Replace 'unknown' with NaN in specified columns\n",
    "    columns_to_replace = ['STREET_ADDRESS', 'CITY', 'STATE', 'REGION', 'POSTAL_CODE', 'COUNTRY']\n",
    "    plant_copy[columns_to_replace] = plant_copy[columns_to_replace].replace('Unknown', np.nan)\n",
    "\n",
    "    # Function to create the location column\n",
    "    def generate_location(row):\n",
    "        if row['LATITUDE'] != 0 and row['LONGITUDE'] != 0:\n",
    "            return f\"{row['LATITUDE']}, {row['LONGITUDE']}\"\n",
    "        else:\n",
    "            address_parts = [\n",
    "                row.get('STREET_ADDRESS'),\n",
    "                row.get('CITY'),\n",
    "                row.get('STATE'),\n",
    "                row.get('REGION'),\n",
    "                row.get('POSTAL_CODE'),\n",
    "                row.get('COUNTRY')\n",
    "            ]\n",
    "            # Filter out None or NaN values and join the address parts\n",
    "            return ', '.join(filter(pd.notna, address_parts))\n",
    "\n",
    "    # Apply the function to create the location column\n",
    "    plant_copy['geo'] = plant_copy.apply(generate_location, axis=1)\n",
    "    plant_copy.rename(columns={'DESCRIPTION': 'SUPPLIER'}, inplace=True)\n",
    "\n",
    "    # Filter final_df for rows where FINAL_COMPONENT_UOM == 'HR'\n",
    "    filtered_final_df = final_df[final_df['FINAL_COMPONENT_UOM'] == 'HR'].reset_index()\n",
    "\n",
    "    # Merge filtered_final_df with plant_copy on PLANT_ID\n",
    "    merged_df = filtered_final_df.merge(plant_copy, on='PLANT_ID', how='left')\n",
    "\n",
    "    # Update Supplier and Geo_1 columns in the original final_df using the original indices\n",
    "    final_df.loc[final_df['FINAL_COMPONENT_UOM'] == 'HR', 'Supplier'] = merged_df['SUPPLIER'].values\n",
    "    final_df.loc[final_df['FINAL_COMPONENT_UOM'] == 'HR', 'Geo_1'] = merged_df['geo'].values\n",
    "\n",
    "    # Initialize the 'is_leaf' column to 'Yes' for all items\n",
    "    final_df['is_leaf'] = 'Yes'\n",
    "\n",
    "    # Iterate over the DataFrame rows to check each item\n",
    "    for i in range(len(final_df) - 1):\n",
    "        # If the next item's level is greater than the current item's level,\n",
    "        # then the current item has a child and is not a leaf\n",
    "        if final_df.loc[i + 1, 'Level'] > final_df.loc[i, 'Level']:\n",
    "            final_df.loc[i, 'is_leaf'] = 'No'\n",
    "\n",
    "    # Iterate through rows in final_df\n",
    "    for index, row in final_df.iterrows():\n",
    "        if row['is_leaf'] == 'No' and row['Level'] != 0:\n",
    "            # Find the next leaf item\n",
    "            next_leaf = final_df.loc[(final_df.index > index) & (final_df['is_leaf'] == 'Yes')].head(1)\n",
    "            if not next_leaf.empty:\n",
    "                next_leaf_plant_id = next_leaf.iloc[0]['PLANT_ID']\n",
    "                # If PLANT_IDs differ, fetch the SUPPLIER and geo from plant_copy DataFrame\n",
    "                if row['PLANT_ID'] != next_leaf_plant_id:\n",
    "                    description = plant_copy.loc[plant_copy['PLANT_ID'] == next_leaf_plant_id, 'SUPPLIER'].values\n",
    "                    geo_1 = plant_copy.loc[plant_copy['PLANT_ID'] == next_leaf_plant_id, 'geo'].values\n",
    "                    if description.size > 0:\n",
    "                        final_df.at[index, 'Supplier'] = description[0]\n",
    "                    if geo_1.size > 0:\n",
    "                        final_df.at[index, 'Geo_1'] = geo_1[0]\n",
    "\n",
    "    # Drop the 'is_leaf' column\n",
    "    final_df.drop(columns=['is_leaf'], inplace=True)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e599bef-6606-437f-86b8-04735aad9765",
   "metadata": {},
   "source": [
    "# Running the Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4988fc53-dc15-45fc-beb2-836b9575516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, plant, plant_loc, CDMS_DATA = load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a244d14f-00d3-47c4-87c2-e8c365221114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.7727978229522705 seconds\n"
     ]
    }
   ],
   "source": [
    "adj_full = create_adj_list(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaae1b78-40ff-4c50-a81c-3359de825001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(component_id):\n",
    "    # Step 1: Build the BOM dataframe\n",
    "    bom_dataframe = build_bom_dataframe(component_id, adj_full, df)\n",
    "    # Step 2: Group and aggregate\n",
    "    bom_dataframe, result_dict = group_and_aggregate(bom_dataframe, component_id, df)\n",
    "    \n",
    "    # Step 3: Scale quantities\n",
    "    bom_dataframe = scale_quantities(bom_dataframe, result_dict)\n",
    "    \n",
    "    # Step 4: Scale input quantities by level\n",
    "    bom_dataframe = scale_input_quantities_by_level(bom_dataframe)\n",
    "    \n",
    "    # Step 5: Add leaf status\n",
    "    bom_dataframe = add_leaf_status(bom_dataframe)\n",
    "    # Step 6: Enrich with supplier geography\n",
    "    bom_dataframe = enrich_with_supplier_geo(plant, plant_loc, bom_dataframe)\n",
    "    # Step 7: Add CDMS matches\n",
    "    bom_dataframe = add_cdms_matches_to_grouped_df(bom_dataframe, CDMS_DATA)\n",
    "    # Step 8: Expand grouped dataframe\n",
    "    bom_dataframe = expand_grouped_df(bom_dataframe)\n",
    "    # Step 9: Final rescaling\n",
    "    bom_dataframe = final_rescaling(bom_dataframe)\n",
    "    \n",
    "    # step 10: extra BOM modifications\n",
    "    \n",
    "    bom_dataframe = extra_bom_modifications(bom_dataframe)\n",
    "    bom_dataframe = extra_bom_modifications_2(bom_dataframe,plant)\n",
    "    return bom_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ff59cca-5b4d-44cd-a8d6-3498e90ee8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1394053"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47cba2de-3a60-419c-b160-bcf98bd22b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>PLANT_ID</th>\n",
       "      <th>COMPONENT_ID</th>\n",
       "      <th>COMPONENT_DESC</th>\n",
       "      <th>COMPONENT_MATERIAL_TYPE</th>\n",
       "      <th>TOTAL_INPUT_QTY</th>\n",
       "      <th>FINAL_COMPONENT_UOM</th>\n",
       "      <th>COMPONENT_MASS_CONV_FACTOR</th>\n",
       "      <th>COMPONENT_MASS_UNIT</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Geo_1</th>\n",
       "      <th>Max_proportion</th>\n",
       "      <th>Name</th>\n",
       "      <th>CAS_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1012</td>\n",
       "      <td>7000121378</td>\n",
       "      <td>49 CL 255GAL DR</td>\n",
       "      <td>FERT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>DR</td>\n",
       "      <td>955.587</td>\n",
       "      <td>KG</td>\n",
       "      <td>3M Cordova</td>\n",
       "      <td>41.7539, -90.2889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1012</td>\n",
       "      <td>Machine-79452N</td>\n",
       "      <td>MACHINE</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>HR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>3M Cordova</td>\n",
       "      <td>41.7539, -90.2889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1012</td>\n",
       "      <td>3010214181</td>\n",
       "      <td>CONTAINER, INTERMEDIATE BULK 275 GAL</td>\n",
       "      <td>VERP</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>EA</td>\n",
       "      <td>57152.600</td>\n",
       "      <td>G</td>\n",
       "      <td>1722699</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1012</td>\n",
       "      <td>4100059230</td>\n",
       "      <td>PSA00871 WIP SS LATEX FASTBOND INPUT</td>\n",
       "      <td>HALB</td>\n",
       "      <td>952.716541</td>\n",
       "      <td>KG</td>\n",
       "      <td>1.000</td>\n",
       "      <td>KG</td>\n",
       "      <td>3M Cordova</td>\n",
       "      <td>41.7539, -90.2889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1012</td>\n",
       "      <td>Machine-79452N</td>\n",
       "      <td>MACHINE</td>\n",
       "      <td>None</td>\n",
       "      <td>1.453862</td>\n",
       "      <td>HR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>3M Cordova</td>\n",
       "      <td>41.7539, -90.2889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>Polyglycol Ether</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>KG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Polyglycol Ether</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>Diethanolamine</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>KG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Diethanolamine</td>\n",
       "      <td>111-42-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>Ethanolamine</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>KG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Ethanolamine</td>\n",
       "      <td>141-43-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>Triethanolamine</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.178115</td>\n",
       "      <td>KG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Triethanolamine</td>\n",
       "      <td>102-71-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>1</td>\n",
       "      <td>1012</td>\n",
       "      <td>3010020524</td>\n",
       "      <td>CONTAINER, INTERMEDIATE BULK</td>\n",
       "      <td>VERP</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>EA</td>\n",
       "      <td>60.780</td>\n",
       "      <td>KG</td>\n",
       "      <td>1720484</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Level PLANT_ID      COMPONENT_ID                        COMPONENT_DESC  \\\n",
       "0         0     1012        7000121378                       49 CL 255GAL DR   \n",
       "1         1     1012    Machine-79452N                               MACHINE   \n",
       "2         1     1012        3010214181  CONTAINER, INTERMEDIATE BULK 275 GAL   \n",
       "3         1     1012        4100059230  PSA00871 WIP SS LATEX FASTBOND INPUT   \n",
       "4         2     1012    Machine-79452N                               MACHINE   \n",
       "...     ...      ...               ...                                   ...   \n",
       "1699      4     None  Polyglycol Ether                                  None   \n",
       "1700      4     None    Diethanolamine                                  None   \n",
       "1701      4     None      Ethanolamine                                  None   \n",
       "1702      4     None   Triethanolamine                                  None   \n",
       "1703      1     1012        3010020524          CONTAINER, INTERMEDIATE BULK   \n",
       "\n",
       "     COMPONENT_MATERIAL_TYPE  TOTAL_INPUT_QTY FINAL_COMPONENT_UOM  \\\n",
       "0                       FERT         1.000000                  DR   \n",
       "1                       None         0.001526                  HR   \n",
       "2                       VERP         0.800000                  EA   \n",
       "3                       HALB       952.716541                  KG   \n",
       "4                       None         1.453862                  HR   \n",
       "...                      ...              ...                 ...   \n",
       "1699                    None         0.001781                  KG   \n",
       "1700                    None         0.000891                  KG   \n",
       "1701                    None         0.000178                  KG   \n",
       "1702                    None         0.178115                  KG   \n",
       "1703                    VERP         0.872000                  EA   \n",
       "\n",
       "      COMPONENT_MASS_CONV_FACTOR COMPONENT_MASS_UNIT    Supplier  \\\n",
       "0                        955.587                  KG  3M Cordova   \n",
       "1                            NaN                None  3M Cordova   \n",
       "2                      57152.600                   G     1722699   \n",
       "3                          1.000                  KG  3M Cordova   \n",
       "4                            NaN                None  3M Cordova   \n",
       "...                          ...                 ...         ...   \n",
       "1699                         NaN                None        None   \n",
       "1700                         NaN                None        None   \n",
       "1701                         NaN                None        None   \n",
       "1702                         NaN                None        None   \n",
       "1703                      60.780                  KG     1720484   \n",
       "\n",
       "                  Geo_1  Max_proportion              Name      CAS_  \n",
       "0     41.7539, -90.2889             NaN               NaN       NaN  \n",
       "1     41.7539, -90.2889             NaN               NaN       NaN  \n",
       "2                    US             NaN               NaN       NaN  \n",
       "3     41.7539, -90.2889             NaN               NaN       NaN  \n",
       "4     41.7539, -90.2889             NaN               NaN       NaN  \n",
       "...                 ...             ...               ...       ...  \n",
       "1699                 US             1.0  Polyglycol Ether            \n",
       "1700                 US             0.5    Diethanolamine  111-42-2  \n",
       "1701                 US             0.1      Ethanolamine  141-43-5  \n",
       "1702                 US           100.0   Triethanolamine  102-71-6  \n",
       "1703                 US             NaN               NaN       NaN  \n",
       "\n",
       "[1704 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bom_dataframe = main('7000121378')\n",
    "bom_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3686fe45-574e-48ce-95c3-bc43416595a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_dataframe.to_excel(\"7000121378_with_cycle_example.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6124884b-6af6-49e4-8439-5efb6acfe106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>PLANT_ID</th>\n",
       "      <th>COMPONENT_ID</th>\n",
       "      <th>COMPONENT_DESC</th>\n",
       "      <th>COMPONENT_MATERIAL_TYPE</th>\n",
       "      <th>TOTAL_INPUT_QTY</th>\n",
       "      <th>FINAL_COMPONENT_UOM</th>\n",
       "      <th>COMPONENT_MASS_CONV_FACTOR</th>\n",
       "      <th>COMPONENT_MASS_UNIT</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Geo_1</th>\n",
       "      <th>Max_proportion</th>\n",
       "      <th>Name</th>\n",
       "      <th>CAS_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>11002103734</td>\n",
       "      <td>VULCANIZED FIBER 0.0335 (DYNOS) CHOCOLATE BROW...</td>\n",
       "      <td>ROH</td>\n",
       "      <td>0.277085</td>\n",
       "      <td>YD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1723730</td>\n",
       "      <td>DE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "      <td>11002103734</td>\n",
       "      <td>VULCANIZED FIBER 0.0335 (DYNOS) CHOCOLATE BROW...</td>\n",
       "      <td>ROH</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>YD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1723730</td>\n",
       "      <td>DE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>11002103734</td>\n",
       "      <td>VULCANIZED FIBER 0.0335 (DYNOS) CHOCOLATE BROW...</td>\n",
       "      <td>ROH</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>YD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1723730</td>\n",
       "      <td>DE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level PLANT_ID COMPONENT_ID  \\\n",
       "318      6     1000  11002103734   \n",
       "637      6     1000  11002103734   \n",
       "957      7     1000  11002103734   \n",
       "\n",
       "                                        COMPONENT_DESC  \\\n",
       "318  VULCANIZED FIBER 0.0335 (DYNOS) CHOCOLATE BROW...   \n",
       "637  VULCANIZED FIBER 0.0335 (DYNOS) CHOCOLATE BROW...   \n",
       "957  VULCANIZED FIBER 0.0335 (DYNOS) CHOCOLATE BROW...   \n",
       "\n",
       "    COMPONENT_MATERIAL_TYPE  TOTAL_INPUT_QTY FINAL_COMPONENT_UOM  \\\n",
       "318                     ROH         0.277085                  YD   \n",
       "637                     ROH         0.000580                  YD   \n",
       "957                     ROH         0.000196                  YD   \n",
       "\n",
       "     COMPONENT_MASS_CONV_FACTOR COMPONENT_MASS_UNIT Supplier Geo_1  \\\n",
       "318                         NaN                None  1723730    DE   \n",
       "637                         NaN                None  1723730    DE   \n",
       "957                         NaN                None  1723730    DE   \n",
       "\n",
       "     Max_proportion Name CAS_  \n",
       "318             NaN  NaN  NaN  \n",
       "637             NaN  NaN  NaN  \n",
       "957             NaN  NaN  NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bom_dataframe[bom_dataframe['COMPONENT_ID'] == '11002103734']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4702675e-02f9-4fe5-b448-90aafc22b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bom_dataframe.to_excel('7000045160.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538d9b1-93fb-4dfa-aeee-31eb70ac4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_dataframe[(bom_dataframe['COMPONENT_ID'] == '1000002305')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "362ea0b2-c379-4a14-ba8f-b9a3dee4a586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material ID</th>\n",
       "      <th>Has Cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000028199</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7012512614</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7100050520</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7100182457</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000045159</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>7100064741</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>7100204776</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>7100219533</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>7010350043</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>7100250733</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Material ID  Has Cycle\n",
       "0    7000028199      False\n",
       "1    7012512614      False\n",
       "2    7100050520      False\n",
       "3    7100182457      False\n",
       "4    7000045159      False\n",
       "..          ...        ...\n",
       "480  7100064741      False\n",
       "481  7100204776      False\n",
       "482  7100219533      False\n",
       "483  7010350043      False\n",
       "484  7100250733      False\n",
       "\n",
       "[485 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "without_cycle = pd.read_excel('without_cycle_2023_updated_2.xlsx')\n",
    "without_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e88050ae-be76-46e6-b98f-ae6bed5b3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_cycle = without_cycle.drop_duplicates(subset='Material ID', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "792bc621-d356-46f0-8fcf-3b683b1ed230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_cycle['Material ID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae5bab64-3eb5-4452-b2f2-09385afed23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material ID</th>\n",
       "      <th>Has Cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000028199</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7012512614</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7100050520</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7100182457</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000045159</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>7100032448</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>7000034390</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>7010347546</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>7100064741</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>7010350043</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Material ID  Has Cycle\n",
       "0    7000028199      False\n",
       "1    7012512614      False\n",
       "2    7100050520      False\n",
       "3    7100182457      False\n",
       "4    7000045159      False\n",
       "..          ...        ...\n",
       "473  7100032448      False\n",
       "478  7000034390      False\n",
       "479  7010347546      False\n",
       "480  7100064741      False\n",
       "483  7010350043      False\n",
       "\n",
       "[355 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#without_cycle['Material ID'] = without_cycle['Material ID'].astype(str)\n",
    "without_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc716105-cff9-4287-a6e1-0e843583d26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating BOMs: 100%|██████████████████████████████████████████████████████████████| 355/355 [4:25:13<00:00, 44.83s/BOM]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0  1000   7000028199      987C 60+ 125 X 22MM SLOT 25/100 DC  FERT  \\\n",
      "0       1  1000  34870543674                            BAG, PLASTIC  VERP   \n",
      "1       1  1000  34871966114                           INSERT, PAPER  VERP   \n",
      "2       1  1000  34871626908          14\" CF WEB WIDTH, 3 MIL OLEFIN  VERP   \n",
      "3       1  1000  44000947885  INPR FIB X5 60+ 3M987C 125 X 22MM SLOT  HALB   \n",
      "4       2  1000   4010038414               987C 60+ X5 FLEX 46.25 IN  HALB   \n",
      "...    ..   ...          ...                                     ...   ...   \n",
      "168799  2   NaN    Magnesium                                     NaN   NaN   \n",
      "168800  2   NaN       Copper                                     NaN   NaN   \n",
      "168801  2   NaN         Iron                                     NaN   NaN   \n",
      "168802  2   NaN    Manganese                                     NaN   NaN   \n",
      "168803  1  1249    VENDORVAL                          OUTSOURCED MFG   NaN   \n",
      "\n",
      "             1.0  YD2  1118.2450532    G  3M Alexandria  45.8694, -95.3755  \\\n",
      "0       2.140258   EA           NaN  NaN        1502191                 US   \n",
      "1       2.140258   EA           NaN  NaN        1067705                 US   \n",
      "2       0.001620   EA           NaN  NaN            NaN                NaN   \n",
      "3       0.998787  YD2           NaN  NaN  3M Alexandria  45.8694, -95.3755   \n",
      "4       1.043839  YD2   2460.910685    G  3M Alexandria  45.8694, -95.3755   \n",
      "...          ...  ...           ...  ...            ...                ...   \n",
      "168799  0.001786   KG           NaN  NaN            NaN                 US   \n",
      "168800  0.000744   KG           NaN  NaN            NaN                 US   \n",
      "168801  0.001950   KG           NaN  NaN            NaN                 US   \n",
      "168802  0.000610   KG           NaN  NaN            NaN                 US   \n",
      "168803  0.005093   HR           NaN  NaN   Southwire Co   38.6737, -88.458   \n",
      "\n",
      "        Unnamed: 11 Unnamed: 12 Unnamed: 13  \n",
      "0               NaN         NaN         NaN  \n",
      "1               NaN         NaN         NaN  \n",
      "2               NaN         NaN         NaN  \n",
      "3               NaN         NaN         NaN  \n",
      "4               NaN         NaN         NaN  \n",
      "...             ...         ...         ...  \n",
      "168799        0.600   Magnesium   7439-95-4  \n",
      "168800        0.250      Copper   7440-50-8  \n",
      "168801        0.655        Iron   7439-89-6  \n",
      "168802        0.205   Manganese   7439-96-5  \n",
      "168803          NaN         NaN         NaN  \n",
      "\n",
      "[168804 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize an empty list to store the DataFrames temporarily\n",
    "chunk_size = 5  # Set chunk size to 10 rows (suitable for your processing time)\n",
    "results_list = []\n",
    "\n",
    "# Open a file to save the final result incrementally\n",
    "#output_file = 'BOM_lists/3M_BOM_list_2023_updated_3.csv'\n",
    "output_file = 'BOM_lists/3M_BOM_list_2023_updated_4.csv'\n",
    "\n",
    "# Wrap the loop with tqdm to show progress bar\n",
    "for i, material_id in enumerate(tqdm(without_cycle['Material ID'], desc=\"Creating BOMs\", unit=\"BOM\")):\n",
    "    result_df = main(material_id)  # Apply the given main() function to each material ID\n",
    "    results_list.append(result_df)  # Append the returned DataFrame to the results list\n",
    "    \n",
    "    # If we reach the chunk size, save and reset the list to free memory\n",
    "    if (i + 1) % chunk_size == 0:\n",
    "        chunk_df = pd.concat(results_list, ignore_index=True)\n",
    "        chunk_df.to_csv(output_file, mode='a', header=not bool(i), index=False)  # Append to CSV file\n",
    "        results_list.clear()  # Clear the list to free memory \n",
    "\n",
    "# At the end, save any remaining results\n",
    "if results_list:\n",
    "    chunk_df = pd.concat(results_list, ignore_index=True)\n",
    "    chunk_df.to_csv(output_file, mode='a', header=not bool(i), index=False)\n",
    "\n",
    "# Print or return the final concatenated DataFrame (optional)\n",
    "final_result_df = pd.read_csv(output_file)  # Read back from the file if needed\n",
    "print(final_result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d5f6264-895e-45da-85f3-9e2ce3508b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a CSV file without a header\n",
    "df_final_boms = pd.read_csv('BOM_lists/3M_BOM_list_2023_updated_4.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1397febd-23e5-4c14-9cf9-073dbb313d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following code removes non-printable cahracters from the BOMs if neeced so that it can be converted to\n",
    "#excel\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to remove non-printable characters\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Use regex to remove non-printable characters\n",
    "        return re.sub(r'[^\\x20-\\x7E]', '', text)  # Keeps printable ASCII characters\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the entire DataFrame\n",
    "df_final_boms = df_final_boms.apply(lambda col: col.map(clean_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ad2d1e0-18c1-49fe-8a17-e9d5fe18cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# New column names\n",
    "new_column_names = [\n",
    "    \"Level\",\"PLANT_ID\", \"COMPONENT_ID\", 'COMPONENT_DESC','COMPONENT_MATERIAL_TYPE' , \"TOTAL_INPUT_QTY\", \"FINAL_COMPONENT_UOM\", 'COMPONENT_MASS_CONV_FACTOR','COMPONENT_MASS_UNIT', \n",
    "     \"Supplier\", \"Geo_1\", \"Max_proportion\", \n",
    "    \"Name\", \"CAS_\"\n",
    "]\n",
    "\n",
    "# Assign the new column names\n",
    "df_final_boms.columns = new_column_names\n",
    "df_final_boms\n",
    "df_final_boms.to_excel('BOM_lists/3M_BOM_list_2023_updated_4.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0eb83-837a-411b-be8c-941ddc69ef47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebd897-cde8-4ae2-a468-c8f6bd6f7396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92c823-21f1-4e6c-a421-c771fb97e826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b827be-d402-4db0-8f34-572b65eaaaca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd9698-0c53-4939-b7f6-8fb848581e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18159c64-ec78-483c-b2b1-d56a26a97534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05c0f4-dfa3-482f-8881-87b3030a5cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14734d-c3c0-42d3-b7a7-7e608da72d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
